{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.024807,
     "end_time": "2019-12-23T17:08:12.875480",
     "exception": false,
     "start_time": "2019-12-23T17:08:12.850673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How to group many small tasks into larger ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.019881,
     "end_time": "2019-12-23T17:08:12.915990",
     "exception": false,
     "start_time": "2019-12-23T17:08:12.896109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Difficulty level**: intermediate\n",
    "* **Time need to lean**: 10 minutes or less\n",
    "* **Key points**:\n",
    "  * Option `trunk_size` groups small tasks into larger ones\n",
    "  * Option `trunk_workers` determines number of workers per master task\n",
    "  * Tasks can be dispatched and executed on multiple nodes on a cluster system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.025882,
     "end_time": "2019-12-23T17:08:12.966262",
     "exception": false,
     "start_time": "2019-12-23T17:08:12.940380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The problem with many small tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.016288,
     "end_time": "2019-12-23T17:08:13.006953",
     "exception": false,
     "start_time": "2019-12-23T17:08:12.990665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "From time to time you may face the problem with many small tasks, such as running millions of simulations or analyzing thousands of genes. Whereas each simulation or analysis takes just a few minutes to complete, the entire analysis will take a long time and needs to be performed on a cluster. However, most cluster systems does not welcome millions or small tasks as managing a large number of jobs can pose management challenges to the scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.017921,
     "end_time": "2019-12-23T17:08:13.041411",
     "exception": false,
     "start_time": "2019-12-23T17:08:13.023490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The bash script approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.017161,
     "end_time": "2019-12-23T17:08:13.075681",
     "exception": false,
     "start_time": "2019-12-23T17:08:13.058520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What users have usually done are running these analysis in batch, which works more or less like the following script if implemented in SoS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 3.223586,
     "end_time": "2019-12-23T17:08:16.319282",
     "exception": false,
     "start_time": "2019-12-23T17:08:13.095696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n"
     ]
    }
   ],
   "source": [
    "input: for_each=dict(batch=range(4))\n",
    "\n",
    "bash: args=f'{{filename}} {batch*4+1} {(batch+1)*4}'\n",
    "   for id in `seq $1 $2`\n",
    "   do\n",
    "      echo \"Processing $id\"\n",
    "   done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.031689,
     "end_time": "2019-12-23T17:08:16.377669",
     "exception": false,
     "start_time": "2019-12-23T17:08:16.345980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `args` option here determines what will be passed to the underlying `bash` command, which should contain `{filename}` as the filename of the temporary file generated by SoS. In this particular example we use\n",
    "\n",
    "```\n",
    "f'{{filename}} {batch*4+1} {(batch+1)*4}'\n",
    "```\n",
    "so that the following bash commands will be executed\n",
    "```\n",
    "bash {filename} 1 4\n",
    "bash {filename} 5 8\n",
    "bash {filename} 9 12\n",
    "bash {filename} 13 16\n",
    "```\n",
    "for substeps with `batch` equals to `0`, `1`, `2` and `3` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.024305,
     "end_time": "2019-12-23T17:08:16.425685",
     "exception": false,
     "start_time": "2019-12-23T17:08:16.401380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have fewer number of jobs, we can submit the shell scripts to a batch system as tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 1.525837,
     "end_time": "2019-12-23T17:08:17.971405",
     "exception": false,
     "start_time": "2019-12-23T17:08:16.445568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input: for_each=dict(batch=range(4))\n",
    "\n",
    "task: queue='localhost'\n",
    "bash: args=f'{{filename}} {batch*4+1} {(batch+1)*4}'\n",
    "   for id in `seq $1 $2`\n",
    "   do\n",
    "      echo \"Processing $id\"\n",
    "   done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.022563,
     "end_time": "2019-12-23T17:08:18.019113",
     "exception": false,
     "start_time": "2019-12-23T17:08:17.996550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The tasks in this example are executed locally but you can send the tasks to a remote host using\n",
    "\n",
    "```\n",
    "task: queue='host'\n",
    "```\n",
    "or\n",
    "```\n",
    "%run -q host\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.018376,
     "end_time": "2019-12-23T17:08:18.063201",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.044825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Grouping SoS tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.021571,
     "end_time": "2019-12-23T17:08:18.104298",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.082727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"bs-callout bs-callout-primary\" role=\"alert\">\n",
    "  <h4>The <code>trunk_size</code> task option</h4>\n",
    "  <p>The <code>trunk_size=n</code> option groups tasks into groups of size `n` before submitting them to an executor. As a special case, if option `trunk_size` is specified but with a value `None`, all tasks from the step will be grouped together.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.022393,
     "end_time": "2019-12-23T17:08:18.148978",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.126585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The aforementioned example can be implemented in a much easier way as follows using the `trunk_size` task option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.14704,
     "end_time": "2019-12-23T17:08:18.324515",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.177475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input: for_each=dict(id=range(16))\n",
    "\n",
    "task: trunk_size=4, queue='localhost'\n",
    "bash: expand=True\n",
    "    echo \"Processing {id+1}\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.03079,
     "end_time": "2019-12-23T17:08:18.386382",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.355592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this example, 15 tasks are generated from 15 substeps, each running a bash script\n",
    "```\n",
    "echo \"Processing {id}\"\n",
    "```\n",
    "with `id` = `0`, ..., `15` respectively.\n",
    "\n",
    "With option `trunk_size=4`, the tasks are grouped into master tasks with names starting with `M5_`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.032756,
     "end_time": "2019-12-23T17:08:18.453491",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.420735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Executing subtasks in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.034986,
     "end_time": "2019-12-23T17:08:18.523818",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.488832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div class=\"bs-callout bs-callout-primary\" role=\"alert\">\n",
    "  <h4>The <code>trunk_workers</code> task option</h4>\n",
    "  <p>The <code>trunk_workers=n</code> option specify the number of concurrent workers in each task. Similar to option <code>-j</code> for commands <code>sos run</code> and <code>sos execute</code>, it accepts the specification of multiple worker processes on multiple nodes. The value of this parameter will affects variables such as <code>nodes</code>, <code>cores</code>, <code>walltime</code> and <code>mem</code> in task templates.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.037462,
     "end_time": "2019-12-23T17:08:18.595570",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.558108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The master tasks by default execute subtasks sequentially. If the master task has a large number of subtasks and there are computing resources available, you can specifying another option `trunk_workers` to set the number of workers for each master task. For example, in the following SoS workflow, the 16 tasks are submitted as a single (master) task and will be processed by two workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.115974,
     "end_time": "2019-12-23T17:08:18.747318",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.631344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input: for_each=dict(id=range(16))\n",
    "\n",
    "task: trunk_size=None, trunk_workers=2, queue='localhost'\n",
    "bash: expand=True\n",
    "    echo \"Processing {id+1}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.033156,
     "end_time": "2019-12-23T17:08:18.811162",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.778006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Executing subtasks on cluster system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.033019,
     "end_time": "2019-12-23T17:08:18.875901",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.842882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When you submit a master task to the cluster system, you typically need to specify the resources needed for tasks, using options `walltime`, `mem` and `cores`. These variables will be translated and expanded in a task template (defined in SoS configuration files).\n",
    "\n",
    "For example, with the following template for a SLURM-based cluster system,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.036661,
     "end_time": "2019-12-23T17:08:18.946546",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.909885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```sh\n",
    "#!/bin/bash\n",
    "#SBATCH --time={walltime}\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --ntasks-per-node={cores}\n",
    "#SBATCH --mem-per-cpu={mem // cores // 1000000000}G\n",
    "#SBATCH --job-name={task}\n",
    "#SBATCH --output=/home/{user_name}/.sos/{task}.out\n",
    "#SBATCH --error=/home/{user_name}/.sos/{task}.err\n",
    "\n",
    "sos execute {task} -v {verbosity} -s {sig_mode} -r {run_mode}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.029087,
     "end_time": "2019-12-23T17:08:19.010769",
     "exception": false,
     "start_time": "2019-12-23T17:08:18.981682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A task with options `mem='1G'` and `walltime='12h'` will populate the template with variables `mem=1000000000` (1G) and `walltime=`01:00:00`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 4.901719,
     "end_time": "2019-12-23T17:08:23.944145",
     "exception": false,
     "start_time": "2019-12-23T17:08:19.042426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\n"
     ]
    }
   ],
   "source": [
    "%run\n",
    "task: mem='1G', walltime='1h'\n",
    "bash:\n",
    "    echo \"Processing data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.027807,
     "end_time": "2019-12-23T17:08:24.003124",
     "exception": false,
     "start_time": "2019-12-23T17:08:23.975317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you group multiple tasks using options `trunk_size` and `trunk_worker`, the template variables will be adjusted automatically. For example,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.028176,
     "end_time": "2019-12-23T17:08:24.058006",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.029830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "input: for_each=dict(id=range(16))\n",
    "\n",
    "task: trunk_size=None, trunk_workers=2, mem='1G', walltime='1h'\n",
    "bash: expand=True\n",
    "    echo \"Processing {id+1}\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.030725,
     "end_time": "2019-12-23T17:08:24.117127",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.086402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "will generate `mem='2000000000' (2G) and `walltime=08:00:00' because two concurrent workers will use double the RAM, and each worker will process 8 tasks sequentially, in a total of 8 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.025898,
     "end_time": "2019-12-23T17:08:24.171326",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.145428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Executing subtasks on multiple computing nodes of a cluster system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.027898,
     "end_time": "2019-12-23T17:08:24.225171",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.197273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you have many small tasks and would like to submit them as a small number or a single job on the cluster system, and would like to make use of multiple nodes to process them, you can specify more than one computing nodes with option `trunk_workers`. In this case, `trunk_workers` should be a list with its length indicating the number of nodes and its elements indicating the number of workers on each node.\n",
    "\n",
    "For example, with the template above, running `sos run test.sos -q slurm_cluster` will create a single master task with 16 subtasks, processed by 8 workers on two computing nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.032725,
     "end_time": "2019-12-23T17:08:24.286912",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.254187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "input: for_each=dict(id=range(16))\n",
    "\n",
    "task: trunk_size=None, trunk_workers=[4, 4], mem='1G', walltime='1h'\n",
    "bash: expand=True\n",
    "    echo \"Processing {id+1}\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.033612,
     "end_time": "2019-12-23T17:08:24.353044",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.319432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Under the hood, sos will\n",
    "\n",
    "1. determine number of nodes and set variable `nodes` to `2`\n",
    "2. adjust `mem` and `walltime` according to number of concurrent and sequential tasks.\n",
    "3. populate the task template with variables `nodes`, `mem`, `walltime` etc\n",
    "4. submit the generated shell script to create a multi-node job\n",
    "5. Because the task is executed on a cluster system, it will automatically recognize the nodes and processes per node, create workers accordingly to process the tasks on multiple nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "papermill": {
     "duration": 0.02949,
     "end_time": "2019-12-23T17:08:24.412391",
     "exception": false,
     "start_time": "2019-12-23T17:08:24.382901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Further reading\n",
    "\n",
    "* [Running workflows on a cluster system](cluster.html) for how to execute an entire workflow on a cluster system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "papermill": {
   "duration": 19.729707,
   "end_time": "2019-12-23T17:08:29.655304",
   "environment_variables": {},
   "exception": null,
   "input_path": "/Users/bpeng1/sos/sos-docs/src/user_guide/trunk_size.ipynb",
   "output_path": "trunk_size.ipynb_rerun.ipynb",
   "parameters": {},
   "start_time": "2019-12-23T17:08:09.925597",
   "version": "1.1.0"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.21.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}